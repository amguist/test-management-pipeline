flows:
  get-source-messages:
    - log: "Preparing to perform a request to Source: ${replaySource.sourceUrl} for reprocessing messages ..."
    - script: groovy
      body: |
        
        import com.google.gson.GsonBuilder
        
        import java.util.Collections
        
        import java.util.function.Function
        import java.util.stream.Collectors
        
        import org.apache.kafka.clients.consumer.ConsumerRecords
        import org.apache.kafka.clients.consumer.KafkaConsumer
        import org.apache.kafka.common.TopicPartition
        
        import java.time.Duration
        
        def splitSource = replaySource.sourceUrl.split('://')
        def schema = splitSource[0]
        def host = splitSource[1].split('/')[0]
        def topic = splitSource[1].split('/')[1]
        
  
        switch(schema) {
          case 'kafka':
            def totalMessagesInTopic = getTotalMessagesForTopic(host, topic)
            replayMessagesFromKafka(host, topic, totalMessagesInTopic)
            break;
          case 'cosmosdb':
            println('Schema is of type Cosmos DB ....')
            break;
          default:
            println('Schema ' + schema + ' is not supported .....' )
            break;
        }
       
        def createKafkaConsumer(host,consumerGroup) {
            def consumer = new KafkaConsumer([
              "bootstrap.servers"      : host,
        
              // Consumer group
              "group.id"               : consumerGroup,
        
              // auto offset management
              "enable.auto.commit"     : "false",

              // serializers
              "value.deserializer"     : "org.apache.kafka.common.serialization.ByteArrayDeserializer",
              "key.deserializer"       : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
            ]) 
            return consumer
        }
        
        def getTotalMessagesForTopic(host, topic) {
            def consumerGroup = "hawkeye-topic-message-count"
        
            def consumer = createKafkaConsumer(host, consumerGroup)
            def partitions = consumer.partitionsFor(topic).
                        stream().
                        map(p -> new TopicPartition(topic, p.partition())).
                        collect(Collectors.toList())
            consumer.assign(partitions);
            consumer.seekToEnd(Collections.emptySet());
            def endPartitions = partitions.
                        stream().
                        collect(Collectors.toMap(Function.identity(), consumer::position));
            consumer.close()
            return partitions.stream().mapToLong(p -> endPartitions.get(p)).sum()
        }
        
        def replayMessagesFromKafka(host, topic, numberOfMessages) { 
            def numberOfMessagesRead = 0
            def keepOnReading = true
            def consumerGroup = "hawkeye-replay-consumer"
        
            def consumer = createKafkaConsumer(host, consumerGroup)
            
            consumer.subscribe([topic] as List<String>)
            consumer.withCloseable {
              while(keepOnReading) {
                def records = consumer.poll Duration.ofMillis(100)
                if ( numberOfMessagesToRead == 0 ) {
                  keepOnReading = false;
                }
                records.each { record ->
                  numberOfMessagesReadSoFar += 1
                  println 'Partition: ' + record.partition() + ', Offset: ' + record.offset()
                  if (numberOfMessagesReadSoFar >= numberOfMessagesToRead) {
                      keepOnReading = false;
                  }
                }
              }
            }
        }