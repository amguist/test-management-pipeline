flows:
  get-source-messages:
    - log: "Preparing to perform a request to Source: ${replaySource.sourceUrl} for reprocessing messages ..."
    - script: groovy
      body: |
        
        import com.google.gson.GsonBuilder
        
        import java.util.Collections
        
        import java.util.function.Function
        import java.util.stream.Collectors
        
        import org.apache.kafka.clients.consumer.ConsumerRecords
        import org.apache.kafka.clients.consumer.KafkaConsumer
        import org.apache.kafka.common.TopicPartition
        
        import java.time.Duration
        
        def splitSource = replaySource.sourceUrl.split('://')
        def schema = splitSource[0]
        def host = splitSource[1].split('/')[0]
        def topic = splitSource[1].split('/')[1]
        def consumerGroup = 'hawkeyeConcord'
        
  
        switch(schema) {
          case 'kafka':
            def consumer = createKafkaConsumer(host, consumerGroup)
            def totalMessagesInTopic = getTotalMessagesForTopic(consumer, topic)
        
            println "Total Number Of Messages is: $totalMessagesInTopic"
            break;
          case 'cosmosdb':
            println('Schema is of type Cosmos DB ....')
            break;
          default:
            println('Schema ' + schema + ' is not supported .....' )
            break;
        }
       
        def createKafkaConsumer(host,consumerGroup) {
            def consumer = new KafkaConsumer([
              "bootstrap.servers"      : host,
        
              // Consumer group
              "group.id"               : consumerGroup,
              "auto.offset.reset"      : "earliest",
        
              // auto offset management
              "enable.auto.commit"     : "true",
              "auto.commit.interval.ms": "1000",

              // serializers
              "value.deserializer"     : "org.apache.kafka.common.serialization.StringDeserializer",
              "key.deserializer"       : "org.apache.kafka.common.serialization.StringDeserializer"
            ]) 
            return consumer
        }
        
        def getTotalMessagesForTopic(consumer, topic) {
            def partitions = consumer.partitionsFor(topic).
                        stream().
                        map(p -> new TopicPartition(topic, p.partition())).
                        collect(Collectors.toList())
            consumer.assign(partitions);
            consumer.seekToEnd(Collections.emptySet());
            def endPartitions = partitions.
                        stream().
                        collect(Collectors.toMap(Function.identity(), consumer::position));
            return 0
        }
        
        def replayMessagesFromKafka(host, topic, consumerGroup) { 
            
        }