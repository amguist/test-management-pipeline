flows:
  get-source-messages:
    - log: "Preparing to perform a request to Source: ${replaySource.sourceUrl} for reprocessing messages ..."
    - script: groovy
      body: |
        
        import com.google.gson.GsonBuilder
        import org.apache.kafka.clients.consumer.ConsumerRecords
        import org.apache.kafka.clients.consumer.KafkaConsumer
        
        def splitSource = replaySource.sourceUrl.split('://')
        def schema = splitSource[0]
        def host = splitSource[1].split('/')[0]
        def topic = splitSource[1].split('/')[1]
        def consumerGroup = 'hawkeyeConcord'
        
  
        switch(schema) {
          case 'kafka':
            replayMessagesFromKafka(host, topic, consumerGroup)
            break;
          case 'cosmosdb':
            println('Schema is of type Cosmos DB ....')
            break;
          default:
            println('Schema ' + schema + ' is not supported .....' )
            break;
        }
        
        
        def replayMessagesFromKafka(host, topic, consumerGroup) { 
            println('Retrieving message(s) from topic: ' + topic)
        
            def consumer = new KafkaConsumer([
              "bootstrap.servers"      : host,
        
              // auto offset management
              "enable.auto.commit"     : "false",

              // serializers
              "value.deserializer"     : "org.apache.kafka.common.serialization.StringDeserializer",
              "key.deserializer"       : "org.apache.kafka.common.serialization.StringDeserializer"
            ])
            def gson = new GsonBuilder().serializeNulls().setPrettyPrinting().create()
        
            // Consume from the supplied topic
            consumer.subscribe([topic])
            ConsumerRecords records = consumer.poll(100)
            records.each { deadletter ->
              def json = gson.fromJson(deadletter.value())
              println("Value Pulled is: " + json)
          }
          consumer.close()
        }