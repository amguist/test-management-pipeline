flows:
  parse-url-definition:
    - script: groovy
      body: |
      
        import java.util.regex.Pattern
        
        import org.apache.kafka.clients.consumer.KafkaConsumer
        import org.apache.kafka.common.TopicPartition
        
        def uri = "${replaySource.sourceUrl}"
        def environment = "${replaySource.environment}"
        
        println "Apply Substitutions to uri: ${uri}\n"
        def uriToParse = applySubstitutions(uri)
        def schema = parseSchemaFromDefinition(uri)
        
        switch(schema) {
          case 'kafka':
            println('Schema is of type Kafka ....')
            def host = resolveHost(schema, environment)
            def consumer = createKafkaConsumer(host)
            def topic = getTopic()
            
            println "Retrieving Messages from topic: ${topic}\n"
            def totalNumberOfMessages = getMessageCountForTopic(consumer, topic)
            println "${topic} has a total of ${totalNumberOfMessages} messages\n"
            break;
          case 'cosmosdb':
            println('Schema is of type Cosmos DB ....')
            def host = resolveHost(schema, environment)
            break;
          default:
            println('Schema ' + schema + ' is not supported .....' )
            break;
        }
        
        def getMessageCountForTopic(consumer, topic) {
          def partitions = consumer.partitionsFor(topic).
              stream().
              map(p -> new TopicPartition(topic, p.partition())).
              collect(Collectors.toList())
          consumer.assign(partitions);
          consumer.seekToEnd(Collections.emptySet());
          def endPartitions = partitions.
              stream().
              collect(Collectors.toMap(Function.identity(), consumer::position));
          consumer.close()
          return partitions.stream().mapToLong(p -> endPartitions.get(p)).sum()
        }
        
        def createKafkaConsumer(host) {
          def consumer = new KafkaConsumer([
              "bootstrap.servers"      : host,
              "group.id"               : "hawkeye-replay-consumer",
              "enable.auto.commit"     : "false",
              "value.deserializer"     : "org.apache.kafka.common.serialization.ByteArrayDeserializer",
              "key.deserializer"       : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
            ]) 
            return consumer
        }
        
        def getTopic() {
          def splitSource = replaySource.sourceUrl.split('://')
          return splitSource[1].split('/')[1]
        }
        
        def isProductionEnvironment(environment) {
          if(environment == 'prod') {
            return true
          }
          return false
        }
        
        def resolveHost(schema, environment) {
          switch(schema) {
            case 'kafka':
              if(isProductionEnvironment(environment)) {
                  return "10.0.0.121:9092"
              } else {
                  return "10.0.0.121:9092" 
              }
              break;
            case 'cosmosdb':
              if(isProductionEnvironment(environment)) {
                  return "" 
              } else {
                  return "" 
              }
              break;
            default:
              println('Schema ' + schema + ' is not supported .....' )
              break; 
          }
        }
      
        def parseSchemaFromDefinition(uri) {
          def splitSource = uri.split('://')
          return splitSource[0]
        }
        
        def applySubstitutions(uri) {
            def pattern = Pattern.compile("\\{([^{}]+)\\}"); 
            def matcher = pattern.matcher(uri)
        
            def substitutedConfig = uri
            while(matcher.find()) {
              def group = matcher.group()
              if(!group.equals("{}")) {
                def key = group.substring(1,group.length() - 1)
                println "Key value to lookup is: ${key}\n"
              }
            }
        }
